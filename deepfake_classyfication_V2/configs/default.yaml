seed: 42
output_dir: outputs/run1
log_output_path: logi.log

# dane
data:
  root: 
    train: C:/Users/lukas/Desktop/MAGISTERKA/praca_dyplomowa/kod_pracy/pictures/Dataset/Train
    test: C:/Users/lukas/Desktop/MAGISTERKA/praca_dyplomowa/kod_pracy/pictures/Dataset/Test
    val: C:/Users/lukas/Desktop/MAGISTERKA/praca_dyplomowa/kod_pracy/pictures/Dataset/Validation
  img_Height: 256 # rozmiar skalowania obrazu przed patche’ami
  img_Width: 256
  patch_size: 32
  num_workers: 8
  train_split: train
  val_split: val
  max_img_no: 200
  mean: [0.48145466, 0.4578275, 0.40821073] # CLIP
  std: [0.26862954, 0.26130258, 0.27577711]


# graf
graph:
  knn_k: 6

# model
model:
  clip_name: "ViT-B/32" # domyślny = "ViT-B/32"
  clip_trainable: false # "zamrożony" = false ➜ brak gradów
  gat:
    in_dim: 512 # zgodny z CLIP projection dim
    hidden_dim: 256
    out_dim: 4
    num_layers: 3
    heads1: 4
    heads2: 4
    dropout: 0.2


# trening
train:
  batch_size_images: 8
  lr: 3e-4
  weight_decay: 0.05
  epochs: 30
  optimizer: "adamw"
  scheduler: "cosine"
  warmup_epochs: 2
  label_smoothing: 0.0
  class_weights: null
